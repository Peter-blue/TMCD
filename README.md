Get start
======


Once again, we did a lot of work on the basis, transforming the single-modal model into a text-led multi-modal model,
building our own data set, expanding the research object under multi-task, multi-scenario and multi-climate conditions, and extending the research problems to disaster assessment,
crop yield prediction and sea level supervision.

Next I will explain the contents of TMCD:
![1](https://github.com/user-attachments/assets/b9de1172-1a50-440b-ba61-5636d56047ca)
As shown in the schematic above, our change detection framework is based on text and image expansion, and features are aggregated by image encoder GDC and text encoder TGL.

![CD123](https://github.com/user-attachments/assets/24aa4a75-db05-418d-9e0f-8215fd5b69ec)
Different from other networks, here we mainly study the multi-task detection (including changes in buildings, farmland, and water) under dark fog conditions, as shown above.


How to use
------
Models
*resnet50
*resnet34

Environment
---------
![1](https://github.com/user-attachments/assets/00c94add-a4fc-4e65-b7c6-caead64d87e0)

![2](https://github.com/user-attachments/assets/d6408a2b-e7d3-40c9-ac15-8d0c4ab8a216)

Datasets processing
------
We generate a new Levi-NC, SYSU-NC, CCLD-NC dataset on the Levi-cd, CCLD,Sysu-cd datasetã€‚
The detailed conversion code is exposed in the main function.

Dataset 
---
You should set your own path in the dataset.

Train
----
multi-modal train.py

Save model
---
We save the model in pth format and also upload it to the main function.

Test
---
Changing the path of the trained model (pth) in output2.py will generate the visual results of the test and save them in the set path.







